// CONFIGURATION FILE

// Pipeline parameter default values, can be modified by user when calling pipeline on command line (e.g. --ont_reads_fq sample_1.fastq) ##
// Alphabetical order, lists the step for the parameter

params.annotation = 'None' 		// Steps 2,3 : Input GTF/GFF genomic annotation
params.bai = "None"			// Step 2 : Unfiltered bam index file input if you want to start from the bam filtering step (Step 2 Bam)
params.bam = "None"			// Step 2 : Unfiltered bam file input if you want to start from the bam filtering step (Step 2 Bam)
params.bambu_outputs = "None"		// Step 4 : Directory to bambu txt outputs from step 3
params.bambu_rds = "None" 		// Step 3 : Directory containing RDS files
params.barcode_thresh = 100		// Step 0 : threshold for initial filtering of barcodes. The number of reads assigned to the barcode must be above this threshold
params.basecall_compute = "gpu"		// Step 1 : CPU vs GPU basecalling
params.basecall_config = "None"		// Step 1 : Desired basecall configuration 
params.basecall_demux = false		// Step 1 : Basecalling demultiplexing
params.basecall_mods = false		// Step 1 : Desired basecaller modifications
params.basecall_path = 'None'		// Step 1 : directory of basecalling data
params.basecall_speed = "hac"		// Step 1 : Desired basecall speed
params.basecall_trim = "none"		// Step 1 : Type of read trimming during basecalling ("all", "primers", "adapters", "none")
params.cdna_kit = "PCS111" 		// Step 2 : cDNA sequencing kit adapters for Pychopper to trim and orient reads
params.contamination_ref = "None"	// Step 2 : Reference file for contamination analysis
params.demultiplex_name = "sample"	// Step 4 : Sample name to use when demultiplexing
params.ercc = "None"			// Step 2 : Want to concatenate ERCC GTF to CHM13 GFF? Add the ERCC gtf file here
params.fai = "None"			// Step 3 : Index file for reference genome
params.housekeeping = 'None' 		// Step 2 : Input bed file for housekeeping genes (RSEQc)
params.intermediate_qc = "None"		// Step 3 : Intermediate QC reports
params.is_chm13 = "False" 		// Steps 2,3 : Logical, is the reference CHM13?
params.is_discovery = "None" 		// Step 3 : Logical, do you want to perform discovery using Bambu? True = Yes
params.mapped_reads_thresh = 0		// Step 2 : Minimum threshold for mapped reads, 0 for no filtering
params.mapq = "0"			// Step 2 : MAPQ filtering threshold for bam files, 0 for no filtering
params.multiqc_config = "None"		// Step 3 : MultiQC configuration file
params.multiqc_input = "None"		// Step 3 : Directory with MultiQC input for making report.
params.n_cells_process = 300		// Step 3 : Number of barcodes (cells) to batch together for bambu processing
params.n_threads = 10			// Step 0 : Number of threads to use for demultiplexing
params.NDR = "auto"			// Step 3 : NDR value for Bambu novel discovery filtering - Leave it on Auto for most applications
params.ont_fq_to_merge = 'None'		// Step c : path to the fastqs to merge into a single fastq
params.ont_reads_fq = 'None'		// Step 2 : Input fastq reads
params.ont_reads_fq_dir = 'None'	// Step 0 : path to the single-cell fastq directory to demultiplex cells
params.ont_reads_txt = 'None'		// Step 2 : Input sequencing summary files
params.out_dir = "output_directory"	// All : Output directory for pipeline results
params.path = 'None'			// Step 2 : Input unzipped "raw" ONT output files
params.prefix = "None"			// Steps 1,2 : Add prefix to all output files
params.qscore_thresh = "9"		// Steps 1,2 : Quality score threshold
params.ref = 'None' 			// Steps 2,3 : Input reference fasta file
params.rseqc_tin = false		// Step 2 : Perform RSEQC TIN?
params.sample_id_table = "None"		// Steps c,0 : tsv containing directories corresponding to samples
params.step = "None" 			// All : Which step of the pipeline to perform. c = Merge fastqs, 0 = Single-cell demultiplexing, 1 = Basecalling, 2 = Pre-processing, 3 = Discovery and quantification, 4 = Merge bambu txt outputs
params.track_reads = "False"		// Step 3 : Logical, Track Bambu read assignments. True = Track. Tracking uses more memory, but allows you to extract reads that align to specific transcripts
params.trim_barcode = "True"		// Step 1 : Trim barcodes (only counts if basecall demultiplexing is enabled)


nextflow {
	launchOpts = '-Xmx50g'
}



process { 

    // Define local execution
    withLabel: local {
        executor='local'
    }

    // Define job scheduler parameters for jobs based on memory computation/memory ##

    withLabel: tiny {
        executor='slurm'
        clusterOptions='--partition normal --time 00:15:00 --account coa_mteb223_uksr --nodes 1 --ntasks 1 --cpus-per-task 4 --mem-per-cpu 4G --exclude rome008'
    }

    withLabel: small {
        executor='slurm'
        clusterOptions='--partition normal --time 1:00:00 --account coa_mteb223_uksr --nodes 1 --ntasks 1 --cpus-per-task 8 --mem-per-cpu 4G --exclude rome008'
    }

    withLabel: medium_small {
        
        executor='slurm'
        clusterOptions='--partition normal --time 23:00:00 --account coa_mteb223_uksr --nodes 1 --ntasks 1 --cpus-per-task 12 --mem-per-cpu 4G --exclude rome008'
        }

    withLabel: medium {
        executor='slurm'
        clusterOptions='--partition normal --time 23:00:00 --account coa_mteb223_uksr --nodes 1 --ntasks 1 --cpus-per-task 16 --mem-per-cpu 4G --exclude rome008'
    }

    withLabel: medium_large {
        executor='slurm'
        clusterOptions='--partition normal --time 23:00:00 --account coa_mteb223_uksr --nodes 1 --ntasks 1 --cpus-per-task 20 --mem-per-cpu 4G --exclude rome008'
    }

    withLabel: large {
        executor='slurm'
        clusterOptions='--partition normal --time 2-00:00:00 --account coa_mteb223_uksr --nodes 1 --ntasks 1 --cpus-per-task 50 --mem-per-cpu 4G --exclude rome008'
    }

    withLabel: huge {
        executor='slurm'
        clusterOptions='--partition normal --time 7-00:00:00 --account coa_mteb223_uksr --nodes 1 --ntasks 1 --cpus-per-task 16 --mem-per-cpu 30G --exclude rome008'
    }

    // Define cluster options for BAMBU_DUSCOVERY and BAMBU_QUANT
    withLabel: huge_long {
        executor='slurm'
        clusterOptions='--partition normal --time 7-00:00:00 --account coa_mteb223_uksr --nodes 1 --mem-per-cpu 41G --ntasks 1 --cpus-per-task 12'
    }

    // Define job scheduler parameters for jobs based on specific processes (organized alphabetically)

    withLabel: bambu_prep_job {
        executor='slurm'
        clusterOptions='--partition normal --time 23:00:00 --account coa_mteb223_uksr --nodes 1 --ntasks 1 --cpus-per-task 12 --mem-per-cpu 16G --exclude rome008'
    }
    
    withLabel: barcoding {
	executor='slurm'
	clusterOptions='--partition normal --time 1-00:00:00 --account coa_mteb223_uksr --nodes 1 --ntasks 8 --mem 50G'
    }
    
    withLabel: cat_barcode_whitelist {
	executor='slurm'
        clusterOptions='--partition normal --time 01:00:00 --account coa_mteb223_uksr --nodes 1 --ntasks 1 --cpus-per-task 4 --mem-per-cpu 20G'
    }

    withLabel: cat_stats {
	executor='slurm'
        clusterOptions='--partition normal --time 01:00:00 --account coa_mteb223_uksr --nodes 1 --ntasks 1 --cpus-per-task 2 --mem-per-cpu 10G'
    }

    withLabel: contamination {
        executor='slurm'
        clusterOptions='--partition normal --time 23:00:00 --account coa_mteb223_uksr --nodes 1 --ntasks 1 --cpus-per-task 50 --mem-per-cpu 10G --exclude rome008'
    }

    withLabel: convert_nanopore {
	executor='slurm'
        clusterOptions='--partition normal --time 05:00:00 --account coa_mteb223_uksr --nodes 1 --ntasks 1 --cpus-per-task 1 --mem-per-cpu 25G'
    }

    withLabel: convert_nanopore_rescue {
	executor='slurm'
        clusterOptions='--partition normal --time 18:00:00 --account coa_mteb223_uksr --nodes 1 --ntasks 1 --cpus-per-task 1 --mem-per-cpu 250G'
    }

    withLabel: count_and_filter_barcodes {
        executor='slurm'
        clusterOptions='--partition normal --time 01:00:00 --account coa_mteb223_uksr --nodes 1 --ntasks 1 --cpus-per-task 1 --mem-per-cpu 2G'
    }

    withLabel: demultiplexing {
	executor='slurm'
	clusterOptions='--partition normal --time 10-00:00:00 --account coa_mteb223_uksr --nodes 1 --ntasks 10 --mem-per-cpu 50G'
    }
    
    withLabel: gpu {
        executor='slurm'
        clusterOptions='--partition P4V12_SKY32M192_L --time 00:15:00 --account gol_mteb223_uksr --gres=gpu:1 --mem 16G'
    }

    withLabel: pipseeker {
        executor='slurm'
        clusterOptions='--partition normal --time 05:00:00 --account coa_mteb223_uksr --nodes 1 --ntasks 1 --cpus-per-task 4 --mem-per-cpu 4G'
    }

    withLabel: pychopper {
        executor='slurm'
        clusterOptions='--partition normal --time 10:15:00 --account coa_mteb223_uksr --nodes 1 --ntasks 1 --cpus-per-task 4 --mem-per-cpu 4G'
    }



    // Define the singularity containers for each process, will pull containers from the cloud

    // Bambu
    withName: "(BAMBU_PREP|BAMBU_DISCOVERY|BAMBU_QUANT)" {
        container = "library://ebbertlab-madeline/pip_single_cell/bambu:sha256.57ac522a378ce28da6397819926f4185ed164382c4df2b1fff93d4c1d3a889b0"
    }

    // Basecalling
    withName: "(FAST5_to_POD5|BASECALL_CPU|BASECALL_CPU_DEMUX|BASECALL_GPU|BASECALL_GPU_DEMUX)" {
        container = "library://ebbertlab-madeline/pip_single_cell/dorado:sha256.93fc58c931ac05d43297eb82e4de0a6e2c73e683153b0b6a2c42e39f3f1f2502"
        // TODO check this
	singularity.runOptions='--nv'
    }

    //Pre-processing
    withName: "(FIX_SEQUENCING_SUMMARY_NAME_WITH_FLOWCELL|UNZIP_AND_CONCATENATE_WITH_FLOWCELL|SEP_DIR_BY_SAMP|CONVERT_NANOPORE|CONVERT_NANOPORE_RESCUE|CAT_BARCODE_WHITELIST|CAT_STATS|PIPSEEKER|DEMULTIPLEX|COMBINE_DEMULTIPLEX|COUNT_AND_FILTER_BARCODES|PYCHOPPER_SC|COMBINE_STATS_BY_SAMP_AND_FLOWCELL)" {
        container = "library://ebbertlab-madeline/pip_single_cell/nanopore:sha256.80d11d0c1550956f3a44332e51ee9c4712d939d212024fd1293975dc324c1c20"
    }
    
    // Nanopore
    withName: "(MAKE_FAI|FIX_SEQUENCING_SUMMARY_NAME|UNZIP_AND_CONCATENATE|MAP_CONTAMINATION_cDNA|GFFCOMPARE|MAKE_INDEX_cDNA|MINIMAP2_cDNA|MINIMAP2_QC|FILTER_BAM|PYCHOPPER|MAKE_TRANSCRIPTOME|MAKE_INDEX_cDNA_CONTAMINATION_CHM13)" {
        container = "library://ebbertlab-madeline/pip_single_cell/nanopore:sha256.80d11d0c1550956f3a44332e51ee9c4712d939d212024fd1293975dc324c1c20"
   }

    // Quality Control
    withName: "(MERGE_QC_REPORT|MAKE_QC_REPORT_TRIM|MAKE_QC_REPORT_NO_TRIM|MULTIQC_GRCh38|MULTIQC_CHM13|RSEQC_TIN|RSEQC_GENE_BODY_COVERAGE|RSEQC_BAM_STAT|RSEQC_READ_GC|CONVERT_GTF_TO_BED12|RSEQC_JUNCTION_ANNOTATION|RSEQC_JUNCTION_SATURATION|RSEQC_READ_DISTRIBUTION|PYCOQC|DECOMPRESS|TRIM_GALORE|CHM13_GTF_ERCC|CHM13_GTF)" {
        container = "library://ebbertlab-madeline/pip_single_cell/quality_control:sha256.303598cdb11777068e57a9afb9f916bc9b33d765f7c09166903f290c5541cc71"
    }

    //TODO: Maybe get rid of?? 
    withName: "(FILTER_BAM_ONLY)" {
        errorStrategy = 'ignore'
    }
}



// Define executor type and maximum queue size for jobs at once ##

executor {

    name="slurm"
    queueSize = 500
//    memory = '200 GB'
//    stageInMode = 'copy'
//    stageOutMode = 'rclone'
}

// Point to singularity image with the tools necessary to run the pipeline

singularity {
    
    enabled = true
}


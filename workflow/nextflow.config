// CONFIGURATION FILE

// Pipeline parameter default values, can be modified by user when calling pipeline on command line (e.g. --ont_reads_fq sample_1.fastq) ##

// Fastq reads directory
params.ont_reads_fq_dir = 'None'

// Input fastq reads
params.ont_reads_fq = 'None'

// Input sequencing summary files
params.ont_reads_txt = 'None'

// Input reference fasta file
params.ref = 'None' 

// Input bed file for housekeeping genes (RSEQc)
params.housekeeping = 'None' 

// Input GTF/GFF genomic annotation
params.annotation = 'None' 

// Output directory for pipeline results
params.out_dir = "output_directory"

// Logical, is the reference CHM13?
params.is_chm13 = "False" 

// Fast5 directory if basecalling data
params.fast5_dir = 'None' 

// Sample id for files being basecalled
params.basecall_id = "None" 

// Basecalling configuration as specified in guppy
params.basecall_config = "None" 

// Want to concatenate ERCC GTF to CHM13 GFF? Add the ERCC gtf file here
params.ercc = "None" 

// cDNA sequencing kit adapters for Pychopper to trim and orient reads
params.cdna_kit = "PCS111" 

// MultiQC configuration file
params.multiqc_config = "None" 

// Logical, do you want to perform discovery using Bambu? True = Yes
params.is_discovery = "None" 

// NDR value for Bambu novel discovery filtering - Leave it on Auto for most applications
params.NDR = "auto" 

// Logical, Track Bambu read assignments. True = Track. Tracking uses more memory, but allows you to extract reads that align to specific transcripts
params.track_reads = "False" 

// MAPQ filtering threshold for bam files, 0 for no filtering
params.mapq = "0" 

// Which step of the pipeline to perform. 1 = Basecalling, 2 = Pre-processing, 3 = Discovery and quantification
params.step = "None" 

// Directory with MultiQC input for making report.
params.multiqc_input = "None" 

// Directory containing RDS files
params.bambu_rds = "None" 

// Index file for reference genome
params.fai = "None" 

// Unfiltered bam file input if you want to start from the bam filtering step
params.bam = "None" 

// Unfiltered bam index file input if you want to start from the bam filtering step
params.bai = "None" 

// Binary boolean parameter to check if user is performing Direct RNAseq analysis
params.is_dRNA = "False"

// Reference file for contamination analysis
params.contamination_ref = "None"

// Sample name to use when demultiplexing
params.demultiplex_name = "sample"

//tsv containing directories corresponding to samples
params.sampleIDtable = "None"

// threshold for initial filtering of barcodes
// the number of reads assigned to the barcode must be above this threshold
params.barcode_thresh = 100

params.n_threads = 10

nextflow {
	launchOpts = '-Xmx50g'
}

process { 

    // Define job scheduler parameters for jobs that require little memory computation/memory ##

    withLabel: tiny {
        executor='slurm'
        clusterOptions='--partition normal --time 00:15:00 --account coa_mteb223_uksr --nodes 1 --ntasks 1 --cpus-per-task 4 --mem-per-cpu 4G --exclude rome008'
    }



    withLabel: small {
        executor='slurm'
        clusterOptions='--partition normal --time 1:00:00 --account coa_mteb223_uksr --nodes 1 --ntasks 1 --cpus-per-task 8 --mem-per-cpu 4G --exclude rome008'
    }



    // Define job scheduler parameters for jobs that require medium computation/memory ##

    withLabel: medium_small {
        
        executor='slurm'
        clusterOptions='--partition normal --time 23:00:00 --account coa_mteb223_uksr --nodes 1 --ntasks 1 --cpus-per-task 12 --mem-per-cpu 4G --exclude rome008'
        }


    withLabel: medium {
        executor='slurm'
        clusterOptions='--partition normal --time 23:00:00 --account coa_mteb223_uksr --nodes 1 --ntasks 1 --cpus-per-task 16 --mem-per-cpu 4G --exclude rome008'
    }

    withLabel: medium_large {
        executor='slurm'
        clusterOptions='--partition normal --time 23:00:00 --account coa_mteb223_uksr --nodes 1 --ntasks 1 --cpus-per-task 20 --mem-per-cpu 4G --exclude rome008'
    }

    // Define job scheduler parameters for jobs that require lots of computation/memory ##

    withLabel: large {
        executor='slurm'
        clusterOptions='--partition normal --time 2-00:00:00 --account coa_mteb223_uksr --nodes 1 --ntasks 1 --cpus-per-task 50 --mem-per-cpu 4G --exclude rome008'
    }



    withLabel: bambu_prep_job {
        executor='slurm'
        clusterOptions='--partition normal --time 23:00:00 --account coa_mteb223_uksr --nodes 1 --ntasks 1 --cpus-per-task 12 --mem-per-cpu 16G --exclude rome008'
    }

    withLabel: huge {
        executor='slurm'
        clusterOptions='--partition normal --time 7-00:00:00 --account coa_mteb223_uksr --nodes 1 --ntasks 1 --cpus-per-task 16 --mem-per-cpu 30G --exclude rome008'
    }

    withLabel: contamination {
        executor='slurm'
        clusterOptions='--partition normal --time 23:00:00 --account coa_mteb223_uksr --nodes 1 --ntasks 1 --cpus-per-task 50 --mem-per-cpu 10G --exclude rome008'
    }

    // Define local execution

    withLabel: local {
        executor='local'
    }

    withLabel: gpu {
        executor='slurm'
        clusterOptions='--partition P4V12_SKY32M192_L --time 00:15:00 --account gol_mteb223_uksr --gres=gpu:1 --mem 16G'
    }

    withLabel: convert_nanopore {
	executor='slurm'
        clusterOptions='--partition normal --time 05:00:00 --account coa_mteb223_uksr --nodes 1 --ntasks 1 --cpus-per-task 1 --mem-per-cpu 25G'
    }

    withLabel: convert_nanopore_rescue {
	executor='slurm'
        clusterOptions='--partition normal --time 10:00:00 --account coa_mteb223_uksr --nodes 1 --ntasks 1 --cpus-per-task 1 --mem-per-cpu 250G'
    }

    withLabel: cat_barcode_whitelist {
	executor='slurm'
        clusterOptions='--partition normal --time 01:00:00 --account coa_mteb223_uksr --nodes 1 --ntasks 1 --cpus-per-task 4 --mem-per-cpu 20G'
    }

    withLabel: cat_stats {
	executor='slurm'
        clusterOptions='--partition normal --time 01:00:00 --account coa_mteb223_uksr --nodes 1 --ntasks 1 --cpus-per-task 2 --mem-per-cpu 10G'
    }

    withLabel: pipseeker {
        executor='slurm'
        clusterOptions='--partition normal --time 01:00:00 --account coa_mteb223_uksr --nodes 1 --ntasks 1 --cpus-per-task 4 --mem-per-cpu 4G'
    }

    withLabel: count_and_filter_barcodes {
        executor='slurm'
        clusterOptions='--partition normal --time 01:00:00 --account coa_mteb223_uksr --nodes 1 --ntasks 1 --cpus-per-task 1 --mem-per-cpu 2G'
    }

    withLabel: demultiplexing {
	executor='slurm'
	clusterOptions='--partition normal --time 10-00:00:00 --account coa_mteb223_uksr --nodes 1 --ntasks 10 --mem-per-cpu 50G'
    }
    
    withLabel: barcoding {
	executor='slurm'
	clusterOptions='--partition normal --time 1-00:00:00 --account coa_mteb223_uksr --nodes 1 --ntasks 8 --mem 50G'
    }
    
    // Define cluster options for BAMBU_DUSCOVERY and BAMBU_QUANT
    withLabel: huge_long {
        executor='slurm'
        clusterOptions='--partition normal --time 7-00:00:00 --account coa_mteb223_uksr --nodes 1 --mem-per-cpu 41G --ntasks 1 --cpus-per-task 12'
    }

    // Define the singularity containers for each process, will pull containers from the cloud

    // Nanopore
    withName: "(MAP_CONTAMINATION_dRNA|MAP_CONTAMINATION_cDNA|GFFCOMPARE|MAKE_INDEX_cDNA|MAKE_INDEX_dRNA|MINIMAP2_cDNA|MINIMAP2_dRNA|MINIMAP2_QC|FILTER_BAM|FILTER_BAM_ONLY|PYCHOPPER|STRINGTIE_ONT_cDNA|MAKE_FAI|MAKE_TRANSCRIPTOME|MAKE_INDEX_cDNA_CONTAMINATION_CHM13|MAKE_INDEX_dRNA_CONTAMINATION_CHM13|MERGE_MATRICES)" {
        container = "library://ebbertlab/nanopore_cdna/nanopore:sha256.df8b78d8644d58861e7ea5c82c218b76845559c0d71fdb45e58d271a349fd045"
    }

    // Quality Control
    withName: "(MULTIQC_GRCh38|MULTIQC_CHM13|RSEQC|PYCOQC|PYCOQC_dRNA|DECOMPRESS|TRIM_GALORE|CHM13_GTF_ERCC|CHM13_GTF)" {
	container = "library://ebbertlab/nanopore_cdna/quality_control:sha256.45fd0d3aa770abea5c195a734c139250f73af2763f8ae10e03c4751143844bb4"
    }

    // Basecalling
    withName: "(BASECALL|GATHER_BASECALL)" {
	container = "library://ebbertlab/nanopore_cdna/dorado:sha256.4cec2a7db51075e2480ac8b75a7b12c4e77727aa779ccb07925d77ed31283cbd"
        singularity.runOptions='--nv'
    }

    // Bambu
    withName: "(BAMBU_PREP|BAMBU_DISCOVERY|BAMBU_QUANT)" {
        container = "library://ebbertlab/nanopore_cdna/bambu:sha256.44e2b6d7282a488b95b132198b7c4ca659c9e8d6a83797493e746aa3a87ecfea"
    }

    //Pre-processing
    //TODO UPDATE WHEN CONTAINTER IS PUBLISHED TO CLOUD
    withName: "(SEP_DIR_BY_SAMP|CONVERT_NANOPORE|CONVERT_NANOPORE_RESCUE|CAT_BARCODE_WHITELIST|CAT_STATS|PIPSEEKER|DEMULTIPLEX|COMNINE_DEMULTIPLES|COUNT_AND_FILTER_BARCODES)" {
	container = "/project/mteb223_uksr/singularity_files/single-cell_preprocessing.sif"
    }

    //TODO: NEED TO ADD A CONTAINER FOR THE pre-processing steps??
    
    withName: "(FILTER_BAM_ONLY)" {
        errorStrategy = 'ignore'
    }
}



// Define executor type and maximum queue size for jobs at once ##

executor {

    name="slurm"
    queueSize = 500
    memory = '200 GB'
    stageInMode = 'copy'
    stageOutMode = 'rclone'
}

// Point to singularity image with the tools necessary to run the pipeline
singularity {
    
    enabled = true
}

